{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ARjWEakjrwbP"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UtGUIh5MsA5V"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P92T9C7ho8a5",
    "outputId": "2ec3c29a-5260-41a6-94c8-bf46c9d0a04e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
      "  \"(https://pypi.org/project/six/).\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.neighbors.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lLpUw430sRrA"
   },
   "source": [
    "Work on AI data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Iq8sVk8nsLuC"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/content/AI Export.csv\",sep=\",\", encoding='cp1252')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EWLLnQTzsaeS"
   },
   "source": [
    "Work on FI data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CEJoeLmssN3Q",
    "outputId": "a6382213-4c3e-46e6-df0b-81675e627537"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (14,15,16,17) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "df2 = pd.read_csv(\"/content/FI Export.csv\",sep=\",\", encoding='cp1252')\n",
    "df2 = df2[df2['AC_MODEL']=='CRJ700']\n",
    "dfFI = df2[['ATA_SYMPTOM', 'ATA_CAUSE', 'INTERRUPTION_REASON', 'CORRECTIVE_ACTION']]\n",
    "#df = pd.read_csv(\"/content/drive/MyDrive/Capstone/Data/FI.csv\",header=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HQ3ZXsnfspNz"
   },
   "source": [
    "AC_MODEL = CRJ700"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oMyXhzmpsoQE"
   },
   "outputs": [],
   "source": [
    "df = df[df['AC_MODEL']=='CRJ700']\n",
    "df = df[['ATA_SYMPTOM', 'ATA_CAUSE', 'INTERRUPTION_REASON', 'CORRECTIVE_ACTION']]\n",
    "df.append(dfFI, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pnIHC3Nns3Ez"
   },
   "outputs": [],
   "source": [
    "df['features'] = df['INTERRUPTION_REASON'].str.cat(df['CORRECTIVE_ACTION'], sep='  ',na_rep=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cU1-tLjkttvn",
    "outputId": "c5b708a8-ebde-4a41-ea93-c3ba8b1471f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.stem import PorterStemmer\n",
    "stemmer = PorterStemmer()\n",
    "def identify_tokens1(df):\n",
    "    comment = df['features']\n",
    "    comment = re.sub(r'\\d',' ',comment)\n",
    "    words = nltk.word_tokenize(comment)\n",
    "    new_words = [stemmer.stem(word) for word in words]\n",
    "    comment = ' '.join(new_words)\n",
    "    return comment\n",
    "df['features_1'] = df.apply(identify_tokens1, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DoHv09sng9ic"
   },
   "outputs": [],
   "source": [
    "df['features_1'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jXUf0zXZie1t"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(max_features=40000,stop_words='english')\n",
    "testb = vectorizer.fit_transform(df['features_1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VIu0pEXMfYRC"
   },
   "outputs": [],
   "source": [
    "#Check weights of tokens inside vectorizer\n",
    "vect_score = np.asarray(testb.mean(axis=0)).ravel().tolist()\n",
    "vect_array = pd.DataFrame({'term': vectorizer.get_feature_names(), 'weight': vect_score})\n",
    "vect_array.sort_values(by='weight',ascending=False,inplace=True)\n",
    "vect_array.to_csv('tfidfWeights_withoutDigits_PorterStemmer.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "REk3_HL5XDyb"
   },
   "outputs": [],
   "source": [
    "#Check frequency of tokens inside vectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(max_features=40000,stop_words='english').fit(df['features_1'])\n",
    "vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yfJJswwguRjp"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = df['features_1']\n",
    "y = df['ATA_CAUSE']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pmCWrd5jj1dT",
    "outputId": "e04c8894-f9b0-408f-c16a-5f533bd7d1dc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25696, 17800)"
      ]
     },
     "execution_count": 19,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DOZwInw8kACG",
    "outputId": "afd9c846-e275-4cd4-b108-e246cdecd68e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x15816 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 7 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 25,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testb[10,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j_NwsehtpgSv",
    "outputId": "28f7a3c5-bd50-4fab-dd28-a9b6e6c51fd5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "ros = RandomOverSampler()\n",
    "X_over_sampled, Y_over_sampled = ros.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tjPrAyPpuv3v",
    "outputId": "d5b106d8-f169-4ca5-9fde-baea4b7bd881"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1862112, 17800)"
      ]
     },
     "execution_count": 22,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_over_sampled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bOVmxpqbqiUp",
    "outputId": "0b446615-1adb-4ce8-bbe2-2704cb4c4191"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('linearsvc',\n",
       "                 LinearSVC(C=1.0, class_weight=None, dual=True,\n",
       "                           fit_intercept=True, intercept_scaling=1,\n",
       "                           loss='squared_hinge', max_iter=1000,\n",
       "                           multi_class='ovr', penalty='l2', random_state=None,\n",
       "                           tol=0.0001, verbose=0))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 23,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "clf = make_pipeline(LinearSVC())\n",
    "clf.fit(X_over_sampled, Y_over_sampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ftlAVrIpD7_v"
   },
   "outputs": [],
   "source": [
    "clfpredicted = clf.predict(X_test)\n",
    "print(metrics.accuracy_score(y_test, clfpredicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LqOm5-Mdbpve"
   },
   "source": [
    "# New Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EF3LpzHKwfB_",
    "outputId": "61b44010-5c74-443a-8545-da3c2f2a7d1f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:667: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6178988326848249\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import metrics\n",
    "\n",
    "pipe = Pipeline([('tfidf',TfidfVectorizer(max_features=40000,stop_words='english')),('clf',CalibratedClassifierCV(LinearSVC()))])\n",
    "# pipe = Pipeline([('tfidf',TfidfVectorizer(max_features=4000,stop_words='english')),('clf', LogisticRegression())])\n",
    "# pipe = Pipeline([('tfidf',TfidfVectorizer(max_features=4000,stop_words='english')),('clf', KNeighborsClassifier())])\n",
    "# pipe = Pipeline([('tfidf',TfidfVectorizer(max_features=4000,stop_words='english')),('clf', DecisionTreeClassifier())])\n",
    "# pipe = Pipeline([('tfidf',TfidfVectorizer(max_features=4000,stop_words='english')),('clf', SVC())])\n",
    "pipe.fit(X_train,y_train)\n",
    "predicted = pipe.predict(X_test)\n",
    "print(metrics.accuracy_score(y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7NQeRYaHIv7m",
    "outputId": "5495ab78-7013-452b-db20-517191202e21"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "261701"
      ]
     },
     "execution_count": 25,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81
    },
    "id": "A8aoAB-1JsAM",
    "outputId": "fe90b4e5-b9cf-4a34-f2d1-6acbda2534fb"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>7931</th>\n",
       "      <th>2411</th>\n",
       "      <th>200</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.300074</td>\n",
       "      <td>0.072748</td>\n",
       "      <td>0.060404</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       7931      2411      200 \n",
       "0  0.300074  0.072748  0.060404"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#probs = pipe.predict_proba(X_test)\n",
    "#best_n = np.argsort(-probs, axis = 1)[3:] \n",
    "b = pd.DataFrame(pipe.predict_proba([identify_tokens1({'features':'# 2 GEN Found Oil TEMP Bulb wire off'})]), columns=pipe.classes_)\n",
    "#b = np.argsort(pipe.classes_, pipe.predict_proba([identify_tokens1({'features':'# 2 GEN Found Oil TEMP Bulb wire off'})])[0])\n",
    "b.sort_values(by=0,axis=1,ascending=False).iloc[:, 0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZlK8iDqObEFs"
   },
   "outputs": [],
   "source": [
    "pipe.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9wZ_dzwk4cNS"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "pipelines = []\n",
    "pipelines.append(('ScaledLR', Pipeline([('tfidf',TfidfVectorizer(max_features=4000,stop_words='english')),('LR', LogisticRegression())])))\n",
    "pipelines.append(('ScaledLDA', Pipeline([('tfidf',TfidfVectorizer(max_features=4000,stop_words='english')),('LDA', KNeighborsClassifier())])))\n",
    "pipelines.append(('ScaledKNN', Pipeline([('tfidf',TfidfVectorizer(max_features=4000,stop_words='english')),('KNN', LogisticRegression())])))\n",
    "pipelines.append(('ScaledCART', Pipeline([('tfidf',TfidfVectorizer(max_features=4000,stop_words='english')),('CART', DecisionTreeClassifier())])))\n",
    "pipelines.append(('ScaledNB', Pipeline([('tfidf',TfidfVectorizer(max_features=4000,stop_words='english')),('NB', GaussianNB())])))\n",
    "pipelines.append(('ScaledSVM', Pipeline([('tfidf',TfidfVectorizer(max_features=4000,stop_words='english')),('SVM', SVC())])))\n",
    "\n",
    "results = []\n",
    "names=[]\n",
    "for name, model in pipelines:\n",
    "    kfold = KFold(n_splits=10)\n",
    "    cv_results = cross_val_score(model, X_train, y_train, cv=kfold, scoring='accuracy')\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)\n",
    "\n",
    "# Compare Algorithms\n",
    "fig = plt.figure()\n",
    "fig.suptitle('Algorithm Comparison')\n",
    "ax = fig.add_subplot(111)\n",
    "plt.boxplot(results)\n",
    "ax.set_xticklabels(names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w-kOWpGp2klA"
   },
   "source": [
    "Use for creating deployment model : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M6yhuZhF2q1S",
    "outputId": "ce5ac57f-01ad-4eca-9ca0-3f4334606268"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (14,15,16,17) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:667: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import metrics\n",
    "import pickle\n",
    "\n",
    "# AI data\n",
    "df = pd.read_csv(\"/content/AI Export.csv\",sep=\",\", encoding='cp1252')\n",
    "df = df[df['AC_MODEL']=='CRJ']\n",
    "df = df[['ATA_SYMPTOM', 'ATA_CAUSE', 'INTERRUPTION_REASON', 'CORRECTIVE_ACTION']]\n",
    "# FI data (Considering AI and FI both have same preprocessing of data)\n",
    "df2 = pd.read_csv(\"/content/FI Export.csv\",sep=\",\", encoding='cp1252')\n",
    "df2 = df2[df2['AC_MODEL']=='CRJ']\n",
    "dfFI = df2[['ATA_SYMPTOM', 'ATA_CAUSE', 'INTERRUPTION_REASON', 'CORRECTIVE_ACTION']]\n",
    "# Append AI and FI data\n",
    "df.append(dfFI, ignore_index=True)\n",
    "\n",
    "df['features'] = df['INTERRUPTION_REASON'].str.cat(df['CORRECTIVE_ACTION'], sep='  ',na_rep=' ')\n",
    "stemmer = PorterStemmer()\n",
    "def identify_tokens1(df):\n",
    "    comment = df['features']\n",
    "    comment = re.sub(r'\\d',' ',comment)\n",
    "    words = nltk.word_tokenize(comment)\n",
    "    new_words = [stemmer.stem(word) for word in words]\n",
    "    comment = ' '.join(new_words)\n",
    "    return comment\n",
    "df['features_1'] = df.apply(identify_tokens1, axis=1)\n",
    "X = df['features_1']\n",
    "y = df['ATA_CAUSE']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "pipe = Pipeline([('tfidf',TfidfVectorizer(max_features=40000,stop_words='english')),('clf',CalibratedClassifierCV(LinearSVC()))])\n",
    "pipe.fit(X_train,y_train)\n",
    "\n",
    "Pkl_Filename = \"linearsvc_model_crj.pkl\"\n",
    "with open(Pkl_Filename, 'wb') as file:  \n",
    "    pickle.dump(pipe, file)\n",
    "print('done')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of DecoupledDataProcessingAndAlgorithmAnalysis.ipynb",
   "provenance": [
    {
     "file_id": "https://github.com/kanishkad123/colabs/blob/main/DataPreProcessingAndAlgorithmAnalysis.ipynb",
     "timestamp": 1615820783052
    }
   ],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
